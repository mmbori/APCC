#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
í•¨ìˆ˜ í¬ì¸í„° ì°¸ì¡° í•´ê²° ìŠ¤í¬ë¦½íŠ¸

ê¸°ëŠ¥:
- new_extract ê²°ê³¼ì˜ assigned_fnì—ì„œ fp_name ì°¸ì¡°ë¥¼ fp_aggregated_map.jsonì„ ì‚¬ìš©í•´ í™•ìž¥
- ìž¬ê·€ì ìœ¼ë¡œ í™•ìž¥í•˜ì—¬ ìµœì¢… í•¨ìˆ˜ ëª©ë¡ ìƒì„±
- ì¤‘ë³µ ì œê±° ë° ì •ë ¬

ì˜ˆì‹œ:
ìž…ë ¥ (struct_fp_parsing.json):
[
  {"fp_name": "xDestroy", "assigned_fn": ["realFunc", "xCleanup"]},
  {"fp_name": "xCleanup", "assigned_fn": ["cleanup1", "cleanup2"]}
]

ìž…ë ¥ (fp_aggregated_map.json):
{
  "xCleanup": ["cleanup1", "cleanup2"]
}

ì¶œë ¥ (resolved.json):
[
  {"fp_name": "xDestroy", "assigned_fn": ["cleanup1", "cleanup2", "realFunc"]},
  {"fp_name": "xCleanup", "assigned_fn": ["cleanup1", "cleanup2"]}
]
"""

import json
import argparse
from pathlib import Path
from typing import Dict, List, Set

# ==========================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ==========================================================

def is_identifier(tok: str) -> bool:
    """ìœ íš¨í•œ C ì‹ë³„ìžì¸ì§€ í™•ì¸"""
    if not tok:
        return False
    if not (tok[0].isalpha() or tok[0] == '_'):
        return False
    return all(c.isalnum() or c == '_' for c in tok)


def normalize_token(tok: str) -> str:
    """
    í† í° ì •ê·œí™”
    
    ìœ ì§€:
    - ì‹ë³„ìž (í•¨ìˆ˜ëª…, ë§¤í¬ë¡œ)
    - NULL, 0
    
    ì œì™¸:
    - ë¹ˆ ë¬¸ìžì—´
    """
    tok = tok.strip()
    
    # NULL, 0 ë³´ì¡´
    if tok in ('0', 'NULL'):
        return tok
    
    # ì‹ë³„ìž í™•ì¸
    if is_identifier(tok):
        return tok
    
    # ê·¸ ì™¸ ì œì™¸
    return ""


# ==========================================================
# Step 1: fp_aggregated_map ë¡œë“œ
# ==========================================================

def load_fp_map(fp_map_path: Path) -> Dict[str, List[str]]:
    """
    fp_aggregated_map.json ë¡œë“œ
    
    Returns:
        {fp_name: [assigned_fn_list]}
    """
    if not fp_map_path.exists():
        print(f"âš ï¸  Warning: {fp_map_path} not found, proceeding without expansion")
        return {}
    
    with open(fp_map_path, 'r', encoding='utf-8') as f:
        fp_map = json.load(f)
    
    # ê°’ì„ setìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì¤‘ë³µ ì œê±°
    normalized_map = {}
    for fp_name, funcs in fp_map.items():
        normalized_set = set()
        for func in funcs:
            normalized = normalize_token(func)
            if normalized:
                normalized_set.add(normalized)
        normalized_map[fp_name] = sorted(normalized_set)
    
    return normalized_map


# ==========================================================
# Step 2: ìž¬ê·€ì  í™•ìž¥
# ==========================================================

def resolve_fp_recursive(
    fp_name: str,
    current_func: str,
    fp_map: Dict[str, List[str]],
    all_fp_names: Set[str],
    cache: Dict[str, Set[str]],
    visiting: Set[str]
) -> Set[str]:
    """
    íŠ¹ì • í•¨ìˆ˜ë¥¼ ìž¬ê·€ì ìœ¼ë¡œ í™•ìž¥
    
    Args:
        fp_name: í˜„ìž¬ ì²˜ë¦¬ ì¤‘ì¸ fp_name (ë¡œê¹…ìš©)
        current_func: í™•ìž¥í•  í•¨ìˆ˜ ì´ë¦„
        fp_map: fp_name -> assigned_fn ë§µ
        all_fp_names: ëª¨ë“  fp_nameì˜ ì§‘í•©
        cache: ë©”ëª¨ì´ì œì´ì…˜ ìºì‹œ
        visiting: ìˆœí™˜ ì°¸ì¡° ê°ì§€ìš© ìŠ¤íƒ
    
    Returns:
        í™•ìž¥ëœ í•¨ìˆ˜ ì§‘í•©
    """
    # ìºì‹œ í™•ì¸
    cache_key = current_func
    if cache_key in cache:
        return cache[cache_key]
    
    # ìˆœí™˜ ì°¸ì¡° ê°ì§€
    if cache_key in visiting:
        print(f"  âš ï¸  Circular reference detected: {current_func}")
        cache[cache_key] = set()
        return set()
    
    # fp_nameì´ ì•„ë‹ˆë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if current_func not in all_fp_names:
        cache[cache_key] = {current_func}
        return {current_func}
    
    # fp_nameì¸ ê²½ìš° í™•ìž¥
    visiting.add(cache_key)
    result: Set[str] = set()
    
    if current_func in fp_map:
        for func in fp_map[current_func]:
            normalized = normalize_token(func)
            if not normalized:
                continue
            
            # ìž¬ê·€ í™•ìž¥
            expanded = resolve_fp_recursive(
                fp_name, func, fp_map, all_fp_names, cache, visiting
            )
            result.update(expanded)
    
    # ë°©ë¬¸ ì™„ë£Œ
    visiting.remove(cache_key)
    
    # ìºì‹œ ì €ìž¥
    cache[cache_key] = result
    return result


def expand_record(
    record: Dict,
    fp_map: Dict[str, List[str]],
    all_fp_names: Set[str],
    verbose: bool = False
) -> Dict:
    """
    ë‹¨ì¼ ë ˆì½”ë“œì˜ assigned_fn í™•ìž¥
    
    Args:
        record: {"fp_name": ..., "assigned_fn": [...]}
        fp_map: fp_aggregated_map
        all_fp_names: ëª¨ë“  fp_name ì§‘í•©
        verbose: ìƒì„¸ ì¶œë ¥
    
    Returns:
        í™•ìž¥ëœ ë ˆì½”ë“œ
    """
    fp_name = record.get("fp_name", "")
    assigned_fn = record.get("assigned_fn", [])
    
    result_set: Set[str] = set()
    cache: Dict[str, Set[str]] = {}
    
    for func in assigned_fn:
        normalized = normalize_token(func)
        if not normalized:
            continue
        
        # ìž¬ê·€ í™•ìž¥
        expanded = resolve_fp_recursive(
            fp_name, normalized, fp_map, all_fp_names, cache, set()
        )
        
        if expanded:
            result_set.update(expanded)
            
            if verbose and normalized in all_fp_names and len(expanded) > 1:
                print(f"   {fp_name}: {normalized} -> {sorted(expanded)}")
    
    # í™•ìž¥ëœ ë ˆì½”ë“œ ìƒì„±
    new_record = dict(record)
    new_record["assigned_fn"] = sorted(result_set)
    
    return new_record


# ==========================================================
# Step 3: ì „ì²´ ë ˆì½”ë“œ í™•ìž¥
# ==========================================================

def expand_all_records(
    records: List[Dict],
    fp_map: Dict[str, List[str]],
    verbose: bool = False
) -> List[Dict]:
    """
    ëª¨ë“  ë ˆì½”ë“œì˜ assigned_fn í™•ìž¥
    
    Args:
        records: ìž…ë ¥ ë ˆì½”ë“œ ë¦¬ìŠ¤íŠ¸
        fp_map: fp_aggregated_map
        verbose: ìƒì„¸ ì¶œë ¥
    
    Returns:
        í™•ìž¥ëœ ë ˆì½”ë“œ ë¦¬ìŠ¤íŠ¸
    """
    # ëª¨ë“  fp_name ìˆ˜ì§‘
    all_fp_names: Set[str] = set()
    for rec in records:
        fp_name = rec.get("fp_name", "")
        if fp_name:
            all_fp_names.add(fp_name)
    
    # fp_mapì— ìžˆëŠ” fp_nameë„ ì¶”ê°€
    all_fp_names.update(fp_map.keys())
    
    if verbose:
        print(f"\nðŸ“Š Total fp_names to consider: {len(all_fp_names)}")
    
    # ê° ë ˆì½”ë“œ í™•ìž¥
    expanded_records = []
    expansion_count = 0
    
    for rec in records:
        fp_name = rec.get("fp_name", "")
        original_funcs = rec.get("assigned_fn", [])
        
        expanded_rec = expand_record(rec, fp_map, all_fp_names, verbose)
        expanded_funcs = expanded_rec.get("assigned_fn", [])
        
        # í™•ìž¥ ì—¬ë¶€ í™•ì¸
        if set(original_funcs) != set(expanded_funcs):
            expansion_count += 1
            if verbose:
                print(f"   âœ“ {fp_name}: {len(original_funcs)} -> {len(expanded_funcs)} functions")
        
        expanded_records.append(expanded_rec)
    
    print(f"\n   Expanded {expansion_count} records")
    
    return expanded_records


# ==========================================================
# ë©”ì¸
# ==========================================================

def main():
    parser = argparse.ArgumentParser(
        description="Resolve function pointer references using fp_aggregated_map.json",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Basic usage
  python3 resolve_fp_references.py --in struct_fp_parsing.json --map fp_aggregated_map.json
  
  # Custom output
  python3 resolve_fp_references.py --in parsing.json --map map.json --out resolved.json
  
  # Verbose mode
  python3 resolve_fp_references.py --in parsing.json --map map.json --verbose

Input format (struct_fp_parsing.json):
  [
    {
      "fp_name": "xDestroy",
      "assigned_fn": ["realFunc", "xCleanup"]
    }
  ]

Input format (fp_aggregated_map.json):
  {
    "xCleanup": ["cleanup1", "cleanup2"]
  }

Output format (resolved.json):
  [
    {
      "fp_name": "xDestroy",
      "assigned_fn": ["cleanup1", "cleanup2", "realFunc"]
    }
  ]
        """
    )
    
    parser.add_argument(
        "--in",
        dest="in_path",
        required=True,
        help="Input JSON file (from new_extract_fp_in_struct.py)"
    )
    parser.add_argument(
        "--map",
        dest="map_path",
        required=True,
        help="fp_aggregated_map.json file"
    )
    parser.add_argument(
        "--out",
        default="struct_fp_resolved.json",
        help="Output JSON file (default: struct_fp_resolved.json)"
    )
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="ìƒì„¸ ì¶œë ¥"
    )
    
    args = parser.parse_args()
    
    # ìž…ë ¥ íŒŒì¼ í™•ì¸
    in_path = Path(args.in_path)
    if not in_path.exists():
        print(f"âŒ Error: Input file not found: {in_path}")
        return 1
    
    map_path = Path(args.map_path)
    
    # JSON ë¡œë“œ
    print(f"ðŸ“– Loading input: {in_path}")
    with open(in_path, "r", encoding="utf-8") as f:
        records = json.load(f)
    
    print(f"   Total records: {len(records)}")
    
    print(f"\nðŸ“– Loading fp_map: {map_path}")
    fp_map = load_fp_map(map_path)
    print(f"   Total fp_names in map: {len(fp_map)}")
    
    # í™•ìž¥
    print(f"\nðŸ”„ Resolving function pointer references...")
    expanded_records = expand_all_records(records, fp_map, args.verbose)
    
    # í†µê³„
    original_count = sum(len(rec.get("assigned_fn", [])) for rec in records)
    expanded_count = sum(len(rec.get("assigned_fn", [])) for rec in expanded_records)
    
    print(f"\nðŸ“Š Statistics:")
    print(f"   Original assigned_fn count: {original_count}")
    print(f"   Expanded assigned_fn count: {expanded_count}")
    print(f"   Expansion ratio: {expanded_count/max(original_count,1):.2f}x")
    
    # í™•ìž¥ëœ ë ˆì½”ë“œ ì˜ˆì‹œ
    if args.verbose:
        print(f"\nðŸ“‹ Sample expanded records:")
        for rec in expanded_records[:5]:
            if len(rec.get("assigned_fn", [])) > 1:
                print(f"   {rec['fp_name']}:")
                print(f"      {rec['assigned_fn']}")
    
    # ì €ìž¥
    print(f"\nðŸ’¾ Saving results...")
    with open(args.out, "w", encoding="utf-8") as f:
        json.dump(expanded_records, f, indent=2, ensure_ascii=False)
    print(f"   âœ“ Saved to: {args.out}")
    
    print(f"\nâœ… Complete!")
    
    return 0


if __name__ == "__main__":
    exit(main())