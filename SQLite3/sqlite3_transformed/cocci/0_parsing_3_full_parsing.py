#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
í•¨ìˆ˜ í¬ì¸í„° ì°¸ì¡° í™•ì¥ ìŠ¤í¬ë¦½íŠ¸ (ê°œì„  ë²„ì „)

ê¸°ëŠ¥:
- filled_parsing.jsonì— ìˆëŠ” ëª¨ë“  fp_nameì„ ëŒ€ìƒìœ¼ë¡œ ì²˜ë¦¬
- fp_nameì´ assigned_fnì— ìˆì„ ê²½ìš° ì¬ê·€ì ìœ¼ë¡œ í™•ì¥
- ì¤‘ë³µ ì œê±° ë° ì •ë ¬

ì˜ˆì‹œ:
ì…ë ¥:
[
  {"fn_name": "func1", "fp_name": "xDestroy", "assigned_fn": ["realFunc", "xCleanup"]},
  {"fn_name": "func2", "fp_name": "xCleanup", "assigned_fn": ["cleanup1", "cleanup2"]}
]

ì¶œë ¥:
[
  {"fn_name": "func1", "fp_name": "xDestroy", "assigned_fn": ["cleanup1", "cleanup2", "realFunc"]},
  {"fn_name": "func2", "fp_name": "xCleanup", "assigned_fn": ["cleanup1", "cleanup2"]}
]

xCleanupì´ í™•ì¥ë˜ì–´ cleanup1, cleanup2ë¡œ ëŒ€ì²´ë¨
"""

import json
import argparse
from pathlib import Path
from typing import Dict, List, Set

# ==========================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ==========================================================

def is_identifier(tok: str) -> bool:
    """ìœ íš¨í•œ C ì‹ë³„ìì¸ì§€ í™•ì¸"""
    if not tok:
        return False
    if not (tok[0].isalpha() or tok[0] == '_'):
        return False
    return all(c.isalnum() or c == '_' for c in tok)


def normalize_token(tok: str) -> str:
    """
    í† í° ì •ê·œí™”
    
    ìœ ì§€:
    - ì‹ë³„ì (í•¨ìˆ˜ëª…, ë§¤í¬ë¡œ)
    - NULL, 0 (2_fillì—ì„œ ìˆ˜ì§‘í•œ ê°’)
    
    ì œì™¸:
    - ë¹ˆ ë¬¸ìì—´
    """
    tok = tok.strip()
    
    # NULL, 0 ë³´ì¡´
    if tok in ('0', 'NULL'):
        return tok
    
    # ì‹ë³„ì í™•ì¸
    if is_identifier(tok):
        return tok
    
    # ê·¸ ì™¸ ì œì™¸
    return ""


# ==========================================================
# Step 0: ëª¨ë“  fp_name ìˆ˜ì§‘
# ==========================================================

def collect_all_fp_names(records: List[Dict]) -> Set[str]:
    """
    filled_parsing.jsonì— ìˆëŠ” ëª¨ë“  ê³ ìœ í•œ fp_name ìˆ˜ì§‘
    
    Returns:
        ëª¨ë“  fp_nameì˜ ì§‘í•©
    """
    fp_names: Set[str] = set()
    
    for rec in records:
        fp_name = rec.get("fp_name", "")
        if fp_name:
            fp_names.add(fp_name)
    
    return fp_names


# ==========================================================
# Step 1: fp_nameë³„ ì§‘ê³„
# ==========================================================

def build_fp_to_assigned_map(records: List[Dict]) -> Dict[str, Set[str]]:
    """
    fp_name -> assigned_fn ì§‘ê³„
    
    ì˜ˆ:
    [
      {"fp_name": "xDestroy", "assigned_fn": ["func1", "func2"]},
      {"fp_name": "xDestroy", "assigned_fn": ["func2", "func3"]},
      {"fp_name": "xCleanup", "assigned_fn": ["cleanup1"]}
    ]
    
    ê²°ê³¼:
    {
      "xDestroy": {"func1", "func2", "func3"},
      "xCleanup": {"cleanup1"}
    }
    """
    fp_map: Dict[str, Set[str]] = {}
    
    for rec in records:
        fp_name = rec.get("fp_name", "")
        if not fp_name:
            continue
        
        # assigned_fn ìˆ˜ì§‘
        for tok in rec.get("assigned_fn", []):
            normalized = normalize_token(tok)
            if normalized:
                fp_map.setdefault(fp_name, set()).add(normalized)
    
    return fp_map


# ==========================================================
# Step 2: ì¬ê·€ì  í™•ì¥
# ==========================================================

def resolve_fp_recursive(
    fp_name: str,
    fp_map: Dict[str, Set[str]],
    all_fp_names: Set[str],
    cache: Dict[str, Set[str]],
    visiting: Set[str]
) -> Set[str]:
    """
    fp_nameì˜ assigned_fnì„ ì¬ê·€ì ìœ¼ë¡œ í™•ì¥
    
    ì˜ˆ:
    - xDestroy -> ["realFunc", "xCleanup"]
    - xCleanup -> ["cleanup1", "cleanup2"]
    
    ê²°ê³¼:
    - xDestroy -> ["realFunc", "cleanup1", "cleanup2"]
    
    Args:
        fp_name: í™•ì¥í•  í•¨ìˆ˜ í¬ì¸í„° ì´ë¦„
        fp_map: fp_name -> assigned_fn ë§µ
        all_fp_names: filled_parsing.jsonì˜ ëª¨ë“  fp_name ì§‘í•©
        cache: ë©”ëª¨ì´ì œì´ì…˜ ìºì‹œ
        visiting: ìˆœí™˜ ì°¸ì¡° ê°ì§€ìš© ìŠ¤íƒ
    
    Returns:
        í™•ì¥ëœ í•¨ìˆ˜ ì§‘í•©
    """
    # ìºì‹œ í™•ì¸
    if fp_name in cache:
        return cache[fp_name]
    
    # ìˆœí™˜ ì°¸ì¡° ê°ì§€
    if fp_name in visiting:
        print(f"  âš ï¸  Circular reference detected: {fp_name}")
        cache[fp_name] = set()
        return set()
    
    # ë°©ë¬¸ í‘œì‹œ
    visiting.add(fp_name)
    
    result: Set[str] = set()
    assigned = fp_map.get(fp_name, set())
    
    for tok in assigned:
        # filled_parsing.jsonì— ìˆëŠ” fp_nameì¸ì§€ í™•ì¸
        if tok in all_fp_names:
            # ì¬ê·€ í™•ì¥
            expanded = resolve_fp_recursive(tok, fp_map, all_fp_names, cache, visiting)
            result.update(expanded)
        else:
            # ì¼ë°˜ í•¨ìˆ˜ ë˜ëŠ” NULL/0
            result.add(tok)
    
    # ë°©ë¬¸ ì™„ë£Œ
    visiting.remove(fp_name)
    
    # ìºì‹œ ì €ì¥
    cache[fp_name] = result
    return result


def build_expanded_fp_map(records: List[Dict]) -> Dict[str, List[str]]:
    """
    ëª¨ë“  fp_nameì— ëŒ€í•´ ì¬ê·€ í™•ì¥ ìˆ˜í–‰
    
    Returns:
        fp_name -> í™•ì¥ëœ assigned_fn ë¦¬ìŠ¤íŠ¸
    """
    # Step 0: ëª¨ë“  fp_name ìˆ˜ì§‘
    all_fp_names = collect_all_fp_names(records)
    
    print(f"\nğŸ“Š Collecting all fp_names:")
    print(f"   Found {len(all_fp_names)} unique fp_names")
    if len(all_fp_names) <= 20:
        print(f"   fp_names: {sorted(all_fp_names)}")
    else:
        sample = sorted(all_fp_names)[:10]
        print(f"   Sample: {sample} ... ({len(all_fp_names)-10} more)")
    
    # Step 1: ì›ì‹œ ì§‘ê³„
    fp_map = build_fp_to_assigned_map(records)
    
    print(f"\nğŸ“Š Initial aggregation:")
    print(f"   fp_names with assigned_fn: {len(fp_map)}")
    
    # Step 2: ì¬ê·€ í™•ì¥
    cache: Dict[str, Set[str]] = {}
    expanded: Dict[str, List[str]] = {}
    
    print(f"\nğŸ”„ Resolving recursive references...")
    
    expansion_count = 0
    
    for fp_name, assigned in fp_map.items():
        result_set: Set[str] = set()
        
        for tok in assigned:
            # all_fp_namesì— ìˆëŠ”ì§€ í™•ì¸ (xë¡œ ì‹œì‘í•˜ì§€ ì•Šì•„ë„ ë¨)
            if tok in all_fp_names:
                # ì¬ê·€ í™•ì¥
                expanded_tokens = resolve_fp_recursive(tok, fp_map, all_fp_names, cache, set())
                result_set.update(expanded_tokens)
                
                if expanded_tokens:
                    expansion_count += 1
                    print(f"   {tok} -> {sorted(expanded_tokens)}")
            else:
                result_set.add(tok)
        
        # ì •ë ¬í•˜ì—¬ ì €ì¥
        expanded[fp_name] = sorted(result_set)
    
    print(f"\n   Total expansions: {expansion_count}")
    
    return expanded


# ==========================================================
# Step 3: ë ˆì½”ë“œë³„ í™•ì¥
# ==========================================================

def expand_records(
    records: List[Dict],
    expanded_map: Dict[str, List[str]],
    all_fp_names: Set[str]
) -> List[Dict]:
    """
    ê° ë ˆì½”ë“œì˜ assigned_fnì—ì„œ fp_nameì„ í™•ì¥ëœ ê°’ìœ¼ë¡œ ëŒ€ì²´
    
    ì…ë ¥:
    {
      "fn_name": "func1",
      "fp_name": "xDestroy",
      "assigned_fn": ["realFunc", "xCleanup", "NULL"]
    }
    
    ì¶œë ¥:
    {
      "fn_name": "func1",
      "fp_name": "xDestroy",
      "assigned_fn": ["NULL", "cleanup1", "cleanup2", "realFunc"]
    }
    """
    expanded_records: List[Dict] = []
    
    for rec in records:
        # ì›ë³¸ ë ˆì½”ë“œ ë³µì‚¬ (line, file ë“± ë³´ì¡´)
        new_rec = dict(rec)
        
        result_set: Set[str] = set()
        
        for tok in rec.get("assigned_fn", []):
            normalized = normalize_token(tok)
            if not normalized:
                continue
            
            # all_fp_namesì— ìˆëŠ” fp_nameì¸ì§€ í™•ì¸
            if normalized in all_fp_names and normalized in expanded_map:
                # fp_nameì´ë©´ í™•ì¥
                result_set.update(expanded_map[normalized])
            else:
                # ì¼ë°˜ í•¨ìˆ˜ ë˜ëŠ” NULL/0
                result_set.add(normalized)
        
        # ì •ë ¬í•˜ì—¬ ì €ì¥
        new_rec["assigned_fn"] = sorted(result_set)
        expanded_records.append(new_rec)
    
    return expanded_records


# ==========================================================
# ë©”ì¸
# ==========================================================

def main():
    parser = argparse.ArgumentParser(
        description="Expand function pointer references in assigned_fn (all fp_names)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python3 0_parsing_3_full_parsing.py --in filled_parsing.json
  python3 0_parsing_3_full_parsing.py --in filled.json --out-map fp_map.json --out-records resolved.json

Input format (from 2_fill_assigned_fn.py):
  [
    {
      "fn_name": "closureAvlDestroy",
      "fp_name": "xDestroy",
      "fp_sequence": 2,
      "assigned_fn": ["closureMemFree", "xCleanup", "NULL"],
      "line": [...],
      "file": "sqlite3.c"
    }
  ]

Output format:
  - out-map: fp_name -> expanded list (all fp_names, not just x-prefixed)
  - out-records: original records with expanded assigned_fn

Changes from original:
  - Processes ALL fp_names found in filled_parsing.json
  - No longer restricted to fp_names starting with 'x'
  - Recursively expands any fp_name that appears in assigned_fn
        """
    )
    
    parser.add_argument(
        "--in",
        default="filled_parsing.json",
        dest="in_path",
        required=True,
        help="Input JSON file (from 2_fill_assigned_fn.py)"
    )
    parser.add_argument(
        "--out-map",
        default="fp_aggregated_map.json",
        help="Output: fp_name -> expanded assigned_fn map (default: fp_aggregated_map.json)"
    )
    parser.add_argument(
        "--out-records",
        default="filled_parsing_resolved.json",
        help="Output: records with expanded assigned_fn (default: filled_parsing_resolved.json)"
    )
    
    args = parser.parse_args()
    
    # ì…ë ¥ íŒŒì¼ í™•ì¸
    in_path = Path(args.in_path)
    if not in_path.exists():
        print(f"âŒ Error: Input file not found: {in_path}")
        return 1
    
    # JSON ë¡œë“œ
    print(f"ğŸ“– Loading: {in_path}")
    with open(in_path, "r", encoding="utf-8") as f:
        records = json.load(f)
    
    print(f"   Total records: {len(records)}")
    
    # Step 0: ëª¨ë“  fp_name ìˆ˜ì§‘
    all_fp_names = collect_all_fp_names(records)
    
    # Step 1: fp_nameë³„ ì§‘ê³„ ë° í™•ì¥
    expanded_map = build_expanded_fp_map(records)
    
    # Step 2: ë ˆì½”ë“œë³„ í™•ì¥
    print(f"\nğŸ“ Expanding records...")
    expanded_records = expand_records(records, expanded_map, all_fp_names)
    
    # í†µê³„
    original_count = sum(len(rec.get("assigned_fn", [])) for rec in records)
    expanded_count = sum(len(rec.get("assigned_fn", [])) for rec in expanded_records)
    
    print(f"\nğŸ“Š Statistics:")
    print(f"   Original assigned_fn count: {original_count}")
    print(f"   Expanded assigned_fn count: {expanded_count}")
    print(f"   Expansion ratio: {expanded_count/max(original_count,1):.2f}x")
    
    # í™•ì¥ëœ ë ˆì½”ë“œ ì˜ˆì‹œ
    print(f"\nğŸ“‹ Sample expanded records:")
    for rec in expanded_records[:3]:
        if len(rec.get("assigned_fn", [])) > 1:
            print(f"   {rec['fn_name']}.{rec['fp_name']}:")
            print(f"      {rec['assigned_fn']}")
    
    # ì €ì¥
    print(f"\nğŸ’¾ Saving results...")
    
    with open(args.out_map, "w", encoding="utf-8") as f:
        json.dump(expanded_map, f, indent=2, ensure_ascii=False)
    print(f"   âœ“ Saved fp_map to: {args.out_map}")
    
    with open(args.out_records, "w", encoding="utf-8") as f:
        json.dump(expanded_records, f, indent=2, ensure_ascii=False)
    print(f"   âœ“ Saved records to: {args.out_records}")
    
    print(f"\nâœ… Complete!")
    print(f"\nâ„¹ï¸  Note: Processed ALL fp_names from filled_parsing.json")
    print(f"   (not limited to x-prefixed names)")
    
    return 0


if __name__ == "__main__":
    exit(main())